"""KARR (Kitt's AI Results Repo) repository management."""

import logging
import subprocess
from pathlib import Path
from typing import Any

import git
from git import Repo

logger = logging.getLogger(__name__)


class KARRRepoManager:
    """Manage KARR (Kitt's AI Results Repo) repositories."""

    @staticmethod
    def create_results_repo(repo_path: Path, hardware_fingerprint: str) -> Repo:
        """Create a new KARR results repository with proper structure.

        Args:
            repo_path: Path for new repo.
            hardware_fingerprint: Hardware fingerprint for this repo.

        Returns:
            Initialized Git repository.
        """
        repo_path.mkdir(parents=True, exist_ok=True)

        repo = git.Repo.init(repo_path)

        KARRRepoManager._init_git_lfs(repo_path)
        KARRRepoManager._create_gitattributes(repo_path)
        KARRRepoManager._create_gitignore(repo_path)
        KARRRepoManager._create_readme(repo_path, hardware_fingerprint)

        (repo_path / "hardware_fingerprint.txt").write_text(hardware_fingerprint)

        repo.index.add(
            [
                ".gitattributes",
                ".gitignore",
                "README.md",
                "hardware_fingerprint.txt",
            ]
        )
        repo.index.commit("Initial commit: KARR results repository")

        return repo

    @staticmethod
    def _init_git_lfs(repo_path: Path) -> None:
        """Initialize Git LFS in repository."""
        try:
            subprocess.run(
                ["git", "lfs", "install"],
                cwd=repo_path,
                check=True,
                capture_output=True,
            )
        except (subprocess.CalledProcessError, FileNotFoundError):
            logger.warning("Git LFS initialization failed - LFS may not be installed")

    @staticmethod
    def _create_gitattributes(repo_path: Path) -> None:
        """Create .gitattributes for LFS tracking."""
        content = """# Track large compressed files with Git LFS
*.jsonl.gz filter=lfs diff=lfs merge=lfs -text
*.log.gz filter=lfs diff=lfs merge=lfs -text
*.bin filter=lfs diff=lfs merge=lfs -text

# Don't track small metadata files with LFS
*.json -filter -diff -merge text
*.md -filter -diff -merge text
*.yaml -filter -diff -merge text
"""
        (repo_path / ".gitattributes").write_text(content)

    @staticmethod
    def _create_gitignore(repo_path: Path) -> None:
        """Create .gitignore."""
        content = """# Python
__pycache__/
*.py[cod]
*$py.class
.Python
*.so

# IDE
.vscode/
.idea/
*.swp
*.swo

# Temp files
*.tmp
*.temp
.DS_Store
"""
        (repo_path / ".gitignore").write_text(content)

    @staticmethod
    def _create_readme(repo_path: Path, hardware_fingerprint: str) -> None:
        """Create README for KARR results repo."""
        content = f"""# KARR - Kitt's AI Results Repo

This repository contains LLM inference benchmark results for the following hardware:

**Hardware Fingerprint**: `{hardware_fingerprint}`

## Structure

```
{repo_path.name}/
├── {{model_name}}/
│   └── {{engine_name}}/
│       └── {{timestamp}}/
│           ├── config.json          # Benchmark configuration
│           ├── metrics.json         # Aggregate metrics
│           ├── summary.md           # Human-readable summary
│           ├── hardware.json        # Detailed hardware info
│           ├── outputs/             # Benchmark outputs (compressed, chunked)
│           └── logs/                # Benchmark logs (compressed, chunked)
```

## Generated By

Results are generated by [KITT (Kirizan's Inference Testing Tools)](https://github.com/user/kitt).

```bash
kitt results submit
```

## Repository Management

### Shallow Clone

```bash
git clone --depth 1 <repo-url>
```

### Cleanup Old Results

```bash
kitt results cleanup --days 90
```

## Hardware Details

See `hardware_fingerprint.txt` for the full system specification.
"""
        (repo_path / "README.md").write_text(content)

    @staticmethod
    def find_results_repo(
        fingerprint: str,
        search_dir: Path | None = None,
    ) -> Path | None:
        """Find existing KARR repo for given fingerprint.

        Searches current directory and parent directories. Handles
        truncated fingerprints by matching prefixes.
        """
        search_dir = search_dir or Path.cwd()

        # Exact match first
        full_name = f"karr-{fingerprint}"
        if (search_dir / full_name).exists():
            return search_dir / full_name

        # Truncated match (karr-{fingerprint[:40]})
        truncated_name = f"karr-{fingerprint[:40]}"
        if (search_dir / truncated_name).exists():
            return search_dir / truncated_name

        # Search for any karr-* directory matching prefix
        for path in search_dir.iterdir():
            if path.is_dir() and path.name.startswith("karr-"):
                fp_file = path / "hardware_fingerprint.txt"
                if fp_file.exists():
                    stored_fp = fp_file.read_text().strip()
                    if (
                        stored_fp == fingerprint
                        or fingerprint.startswith(stored_fp)
                        or stored_fp.startswith(fingerprint)
                    ):
                        return path

        # Search parent directories
        for parent in search_dir.parents:
            for name in [full_name, truncated_name]:
                if (parent / name).exists():
                    return parent / name
            if parent == parent.parent:
                break

        return None

    @staticmethod
    def store_results(
        repo_path: Path,
        model_name: str,
        engine_name: str,
        timestamp: str,
        files: dict,
    ) -> None:
        """Store result files in the KARR repo structure and commit.

        Args:
            repo_path: Path to KARR repository.
            model_name: Name of the model tested.
            engine_name: Name of the engine used.
            timestamp: Timestamp string for this run.
            files: Dict of {filename: content} to store.
        """
        result_dir = repo_path / model_name / engine_name / timestamp
        result_dir.mkdir(parents=True, exist_ok=True)

        for filename, content in files.items():
            filepath = result_dir / filename
            filepath.parent.mkdir(parents=True, exist_ok=True)
            if isinstance(content, bytes):
                filepath.write_bytes(content)
            else:
                filepath.write_text(str(content))

        # Use subprocess for git add/commit to preserve LFS filters
        rel_dir = str(result_dir.relative_to(repo_path))
        try:
            subprocess.run(
                ["git", "add", rel_dir],
                cwd=repo_path,
                check=True,
                capture_output=True,
            )
            subprocess.run(
                [
                    "git",
                    "commit",
                    "-m",
                    f"Add results: {model_name}/{engine_name}/{timestamp}",
                ],
                cwd=repo_path,
                check=True,
                capture_output=True,
            )
            logger.info(f"Results committed in {result_dir}")
        except subprocess.CalledProcessError as e:
            logger.warning(f"Git commit failed: {e}")

        logger.info(f"Results stored in {result_dir}")

    @staticmethod
    def list_results(repo_path: Path) -> list:
        """List all result sets in a KARR repository.

        Returns:
            List of dicts with model, engine, timestamp, and path.
        """
        results: list[dict[str, Any]] = []
        if not repo_path.exists():
            return results

        for model_dir in sorted(repo_path.iterdir()):
            if not model_dir.is_dir() or model_dir.name.startswith("."):
                continue
            for engine_dir in sorted(model_dir.iterdir()):
                if not engine_dir.is_dir():
                    continue
                for ts_dir in sorted(engine_dir.iterdir()):
                    if not ts_dir.is_dir():
                        continue
                    metrics_file = ts_dir / "metrics.json"
                    results.append(
                        {
                            "model": model_dir.name,
                            "engine": engine_dir.name,
                            "timestamp": ts_dir.name,
                            "path": ts_dir,
                            "has_metrics": metrics_file.exists(),
                        }
                    )
        return results
